<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="https://eleutherai.github.io/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="https://eleutherai.github.io/css/styles.css">
    
    
    <title>Eleuther AI site | Projects-intros</title>
</head><body><header class="header-container">
    <div class="content-wrapper">
        <div class="slide-menu" id="sliderMenu">
        
        
          
          
          
          
          <a href="/" class="">Home</a>
        
          
          
          
          
          <a href="/about/" class="">About</a>
        
          
          
          
          
          <a href="/blog/" class="">Blog</a>
        
          
          
          
          
          <a href="/publications/" class="">Publications</a>
        
          
          
          
          
          <a href="/get-involved/" class="">Get Involved</a>
        
        </div>
        <div class="logo-container left">
            <div class="mobile-button" id="mobileButton"><img src="https://eleutherai.github.io/images/mobile-menu-icon.svg" alt="mobile menu icon"></div>
            <h1 class="logo">
                <a href="https://eleutherai.github.io/">
                    <img src="https://eleutherai.github.io/images/eai_logo.png" alt="logo">
                    <span class="logo-text">EleutherAI</span>
                </a>
            </h1>
        </div>
        <div id="nav-border" class="nav-container right">
            <nav id="nav" class="navigation">
                
                
                  
                  
                  
                  
                  <a href="/" class="">Home</a>
                
                  
                  
                  
                  
                  <a href="/about/" class="">About</a>
                
                  
                  
                  
                  
                  <a href="/blog/" class="">Blog</a>
                
                  
                  
                  
                  
                  <a href="/publications/" class="">Publications</a>
                
                  
                  
                  
                  
                  <a href="/get-involved/" class="">Get Involved</a>
                
            </nav>
        </div>
    </div>
    <div class="dark-overlay" id="darkOverlay"></div>
</header>

<div id="content">
<div class="main-container">
    <div class="content-wrapper">
        <div class="grid-1-1">
            <div class="page-content">
                <h2>Blog</h2>
                
                <div class="post">
                    

<i data-feather="calendar"></i>
<time datetime="2019-04-26">Apr 26, 2019</time>

                    <h3><a class="title" href="/projects-intros/open-web-text2/">Open Web Text 2</a></h3>
                    <p>Open Web Text 2 The core principle of WebText is to build a high-quality internet dataset by extracting URLs from Reddit submissions, scraping the URLs, and then performing filtering for quality (by upvotes) &amp; deduplication. As the dataset collected for training the original GPT-2 is not public, researchers independently reproduced the pipeline and released the resulting dataset, called OpenWebTextCorpus (OWT).
OpenWebText2 (OWT2) is an enhanced version of the original OpenWebTextCorpus covering all Reddit submissions from 2005 up until April 2020, with further months becoming available after the corresponding PushShift dump files are released.</p>
                </div>
                
                <div class="post">
                    

<i data-feather="calendar"></i>
<time datetime="2019-03-26">Mar 26, 2019</time>

                    <h3><a class="title" href="/projects-intros/the-pile/">The Pile</a></h3>
                    <p>The Pile The Pile is a large, diverse, open source language modelling data set that consists of many smaller datasets combined together. The objective is to obtain text from as many modalities as possible to ensure that models trained using The Pile will have much broader generalization abilities.
The Pile is now complete! Check it out here.</p>
                </div>
                
                <div class="post">
                    

<i data-feather="calendar"></i>
<time datetime="2019-02-26">Feb 26, 2019</time>

                    <h3><a class="title" href="/projects-intros/gpt-neo/">Gpt-Neo</a></h3>
                    <p>GPT-Neo GPT-Neo is the name of our codebase for transformer-based language models loosely styled around the GPT architecture. One of our goals is to use GPT-Neo to replicate a GPT-3 sized model and open source it to the public, for free. Along the way we will be running experiments with alternative architectures and attention types, releasing any intermediate models, and writing up any findings on our blog. Our models are built in Mesh TensorFlow, which will allow us to scale up to GPT-3 sizes and beyond using simultaneous model and data parallelism.</p>
                </div>
                
            </div>
        </div>  
    </div>
</div>


        </div><div class="main-container">
    <div class="content-wrapper">
        <div class="grid-1-1">    
            <p class="footer-text">Copyright (c) 2021 EleutherAI</p>
        </div>
    </div>
</div>
<script src="https://eleutherai.github.io/js/scripts.js"></script>
</body>
</html>